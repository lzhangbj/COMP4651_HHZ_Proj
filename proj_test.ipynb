{"cells":[{"cell_type":"markdown","source":["### 1. Data Processing\n#### 1.1 Data Load"],"metadata":{}},{"cell_type":"code","source":["train_df = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/train.csv')\nbuilding_metadata_df = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/building_metadata.csv')\nweather_train_df = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/weather_train.csv')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["test_df = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/test.csv')\nbuilding_metadata_df = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/building_metadata.csv')\nweather_test_df = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/weather_test.csv')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["meta_train_df =  building_metadata_df.join(train_df, (building_metadata_df['building_id'] == train_df['building_id']))\ncond = [weather_train_df.site_id == meta_train_df.site_id, weather_train_df.timestamp == meta_train_df.timestamp]\ntrainDF =  weather_train_df.join(meta_train_df, cond)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["meta_test_df =  building_metadata_df.join(test_df, (building_metadata_df['building_id'] == test_df['building_id']))\ncond = [weather_test_df.site_id == meta_test_df.site_id, weather_test_df.timestamp == meta_test_df.timestamp]\ntestDF =  weather_test_df.join(meta_test_df, cond)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["datasetDF = trainDF.drop(\"timestamp\", \"site_id\", \"building_id\")\ndatasetDF = datasetDF.na.fill(0)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["datasetTestDF = testDF.drop(\"timestamp\", \"site_id\", \"building_id\")\ndatasetTestDF = datasetTestDF.na.fill(0)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["split15DF, split85DF = datasetDF.randomSplit([15., 85.], seed=190)\n\n# Let's cache these datasets for performance\ntestSetDF = split15DF.cache()\ntrainingSetDF = split85DF.cache()\nsubmitSetDF = datasetTestDF.cache()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["### 2. ML and Evaluation Set Up"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.sql.functions import col, log, avg\nfrom pyspark.ml.evaluation import Evaluator, RegressionEvaluator\nfrom math import sqrt\nfrom statistics import mean\n# cross validation\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# ***** vectorizer MODEL ****\nfrom pyspark.ml.feature import VectorAssembler\n\nvectorizer = VectorAssembler()\nvectorizer.setInputCols([\"air_temperature\", \"cloud_coverage\", \"dew_temperature\", \"precip_depth_1_hr\", \"sea_level_pressure\", \n                         \"wind_direction\", \"wind_speed\", \"square_feet\", \"year_built\", \"floor_count\", \"meter\"])\nvectorizer.setOutputCol(\"features\")\n\nclass RMSLEEvaluator(Evaluator):\n\n    def __init__(self, predictionCol=\"prediction\", labelCol=\"label\"):\n        self.predictionCol = predictionCol\n        self.labelCol = labelCol\n\n    def _evaluate(self, dataset):\n        \"\"\"\n        Returns a random number. \n        Implement here the true metric\n        \"\"\"\n        new_dataset = dataset.withColumn('result_'+self.predictionCol, log(col(self.predictionCol)+1))\n        new_dataset = new_dataset.withColumn('result_'+self.labelCol, log(col(self.labelCol)+1))\n        new_dataset = new_dataset.withColumn('result', (col('result_'+self.predictionCol) - col('result_'+self.labelCol))**2)\n        \n        result = new_dataset.agg(avg(col(\"result\")))\n        result = result.collect()[0][\"avg(result)\"]\n        return sqrt(result)\n      \n    def isLargerBetter(self):\n        return True"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["#### 2.1 Linear Regression\n##### 2.1.1 Linear Regression Pipeline"],"metadata":{}},{"cell_type":"code","source":["# ***** LINEAR REGRESSION MODEL ****\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.regression import LinearRegressionModel\n# Let's initialize our linear regression learner\nlr = LinearRegression()\n\n# Now we set the parameters for the method\nlr.setPredictionCol(\"predicted_meter_reading\")\\\n  .setLabelCol(\"meter_reading\")\\\n  .setMaxIter(100)\\\n  .setRegParam(0.15)\n\n# We will use the new spark.ml pipeline API. If you have worked with scikit-learn this will be very familiar.\nlrPipeline = Pipeline()\n\nlrPipeline.setStages([vectorizer, lr])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[124]: Pipeline_66341b1e31ee</div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["#### 2.1.2 Linear Regression Simple Fitting"],"metadata":{}},{"cell_type":"code","source":["# Let's first train on the entire dataset to see what we get\nlrModel = lrPipeline.fit(trainingSetDF)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["#### 2.1.3 Linear Regression Simple Evaluation"],"metadata":{}},{"cell_type":"code","source":["# The intercept is as follows:\nintercept = lrModel.stages[1].intercept\n\n# The coefficents (i.e., weights) are as follows:\nweights = lrModel.stages[1].coefficients\n\n# Create a list of the column names (without PE)\nfeaturesNoLabel = [col for col in datasetDF.columns if col != \"meter_reading\" and col != \"primary_use\"]\n\n# Merge the weights and labels\ncoefficents = zip(weights, featuresNoLabel)\n\nequation = \"y = {intercept}\".format(intercept=intercept)\nvariables = []\nfor x in coefficents:\n    weight = abs(x[0])\n    name = x[1]\n    symbol = \"+\" if (x[0] > 0) else \"-\"\n    equation += (\" {} ({} * {})\".format(symbol, weight, name))\n\n# Finally here is our equation\nprint(\"Linear Regression Equation: \" + equation)\n\nresultsDF = lrModel.transform(testSetDF)\n# Create an RMSE evaluator using the label and predicted columns\nregEval = RMSLEEvaluator(predictionCol=\"predicted_meter_reading\", labelCol=\"meter_reading\")\n\n# Run the evaluator on the DataFrame\nrmsle = regEval.evaluate(resultsDF)\n\nprint(\"Simple Root Mean Squared Logarithmtic Error: %.2f\" % rmsle)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Linear Regression Equation: y = -1628.2595464557123 - (81.46769056147313 * air_temperature) + (310.7297353564789 * cloud_coverage) + (49.07117327556077 * dew_temperature) + (0.6854023839988548 * precip_depth_1_hr) - (1.3102359625713624 * sea_level_pressure) - (2.0478121225731805 * wind_direction) + (616.6811932978468 * wind_speed) + (0.031227447032164648 * square_feet) - (1.1441196672897695 * year_built) - (331.46445928163524 * floor_count) + (2458.9197918047203 * meter)\nSimple Root Mean Squared Logarithmtic Error: 4.26\n</div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["#### 2.1.4 Linear Regression Cross Validation Fitting"],"metadata":{}},{"cell_type":"code","source":["# We can reuse the RegressionEvaluator, regEval, to judge the model based on the best Root Mean Squared Error\n# Let's create our CrossValidator with 3 fold cross validation\ncrossval = CrossValidator(estimator=lrPipeline, evaluator=regEval, numFolds=3)\n\n# Let's tune over our regularization parameter from 0.05 to 0.50\nregParam = [x / 200.0 for x in range(1, 11)]\n\n# We'll create a paramter grid using the ParamGridBuilder, and add the grid to the CrossValidator\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, regParam)\n             .build())\ncrossval.setEstimatorParamMaps(paramGrid)\n\n# Now let's find and return the best model\ncvModel = crossval.fit(trainingSetDF).bestModel"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n</div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["#### 2.1.5 Linear Regression Cross Validation Evaluation"],"metadata":{}},{"cell_type":"code","source":["# evaluation\nresultsDF = lrModel.transform(testSetDF)\n# Create an RMSE evaluator using the label and predicted columns\nregEval = RMSLEEvaluator(predictionCol=\"predicted_meter_reading\", labelCol=\"meter_reading\")\n\n# Run the evaluator on the DataFrame\nrmsle = regEval.evaluate(resultsDF)\n\nprint(\"Cross Validated Root Mean Squared Logarithmtic Error: %.2f\" % rmsle)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Cross Validated Root Mean Squared Logarithmtic Error: 4.26\n</div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["### 2.2 Decision Tree\n#### 2.2.1 Decision Tree Pipeline"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.regression import DecisionTreeRegressor\n\n# Create a DecisionTreeRegressor\ndt = DecisionTreeRegressor()\n\ndt.setPredictionCol(\"predicted_meter_reading\")\\\n  .setLabelCol(\"meter_reading\")\\\n  .setFeaturesCol(\"features\")\\\n  .setMaxBins(100)\n\n# Create a Pipeline\ndtPipeline = Pipeline()\n\n# Set the stages of the Pipeline\ndtPipeline.setStages([vectorizer, dt])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[129]: Pipeline_d6d91e7c6927</div>"]}}],"execution_count":22},{"cell_type":"markdown","source":["#### 2.2.2 Decision Tree Simple Fitting"],"metadata":{}},{"cell_type":"code","source":["# Let's first train on the entire dataset to see what we get\ndtModel = dtPipeline.fit(trainingSetDF)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["#### 2.2.3 Decision Tree Simple Evaluation"],"metadata":{}},{"cell_type":"code","source":["resultsDF = dtModel.transform(testSetDF)\n# Create an RMSE evaluator using the label and predicted columns\nregEval = RMSLEEvaluator(predictionCol=\"predicted_meter_reading\", labelCol=\"meter_reading\")\n\n# Run the evaluator on the DataFrame\nrmsle = regEval.evaluate(resultsDF)\n\nprint(\"Simple Root Mean Squared Logarithmtic Error: %.2f\" % rmsle)\n\n# dtSubmitted = dtModel.transform(datasetTestDF)\n# dtSubmitted = dtSubmitted.select('row_id', 'predicted_meter_reading')\n# dtSubmitted = dtSubmitted.withColumnRenamed('predicted_meter_reading', \"meter_reading\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":26},{"cell_type":"code","source":["# file='/FileStore/tables/my.csv'\n# dtSubmitted = dtSubmitted.repartition(1)\n   \n# dtSubmitted.write.format(\"com.databricks.spark.csv\")\\\n#    .option(\"header\", \"true\")\\\n#    .save(file)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"markdown","source":["#### 2.2.4 Decision Tree Cross Validation Fitting"],"metadata":{}},{"cell_type":"code","source":["# Let's just reuse our CrossValidator with the new dtPipeline, RegressionEvaluator regEval, and 3 fold cross validation\ncrossval.setEstimator(dtPipeline)\n\n# Let's tune over our dt.maxDepth parameter on the values 2 and 3, create a paramter grid using the ParamGridBuilder\nparamGrid = (ParamGridBuilder()\n             .addGrid(dt.maxDepth, [2,3,4,5])\n             .build())\n\n# Add the grid to the CrossValidator\ncrossval.setEstimatorParamMaps(paramGrid)\n\n# Now let's find and return the best model\ndtModel = crossval.fit(trainingSetDF).bestModel"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["#### 2.2.5 Decision Tree Cross Validation Evaluation"],"metadata":{}},{"cell_type":"code","source":["# evaluation\nresultsDF = dtModel.transform(testSetDF)\n# Create an RMSE evaluator using the label and predicted columns\nregEval = RMSLEEvaluator(predictionCol=\"predicted_meter_reading\", labelCol=\"meter_reading\")\n\n# Run the evaluator on the DataFrame\nrmsle = regEval.evaluate(resultsDF)\n\nprint(\"Cross Validated Root Mean Squared Logarithmtic Error: %.2f\" % rmsle)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Cross Validated Root Mean Squared Logarithmtic Error: 2.74\n</div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["### 2.3 Random Forest\n#### 2.3.1 Random Forest Pipeline"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.regression import RandomForestRegressor\n\n# Create a DecisionTreeRegressor\nrf = RandomForestRegressor()\n\nrf.setPredictionCol(\"predicted_meter_reading\")\\\n  .setLabelCol(\"meter_reading\")\\\n  .setFeaturesCol(\"features\")\\\n  .setMaxBins(100)\n\n# Create a Pipeline\nrfPipeline = Pipeline()\n\n# Set the stages of the Pipeline\nrfPipeline.setStages([vectorizer, rf])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[134]: Pipeline_2c7e26611cdc</div>"]}}],"execution_count":33},{"cell_type":"markdown","source":["#### 2.3.2 Random Forest Simple Fitting"],"metadata":{}},{"cell_type":"code","source":["# Let's first train on the entire dataset to see what we get\nrfModel = rfPipeline.fit(trainingSetDF)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"markdown","source":["#### 2.3.3 Random Forest Simple Evaluation"],"metadata":{}},{"cell_type":"code","source":["resultsDF = rfModel.transform(testSetDF)\n# Create an RMSE evaluator using the label and predicted columns\nregEval = RMSLEEvaluator(predictionCol=\"predicted_meter_reading\", labelCol=\"meter_reading\")\n\n# Run the evaluator on the DataFrame\nrmsle = regEval.evaluate(resultsDF)\n\nprint(\"Simple Root Mean Squared Logarithmtic Error: %.2f\" % rmsle)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Simple Root Mean Squared Logarithmtic Error: 2.83\n</div>"]}}],"execution_count":37},{"cell_type":"markdown","source":["#### 2.3.4 Random Forest Cross Validation Fitting"],"metadata":{}},{"cell_type":"code","source":["# Let's just reuse our CrossValidator with the new dtPipeline, RegressionEvaluator regEval, and 3 fold cross validation\ncrossval.setEstimator(rfPipeline)\n\n# Let's tune over our dt.maxDepth parameter on the values 2 and 3, create a paramter grid using the ParamGridBuilder\nparamGrid = (ParamGridBuilder()\n             .addGrid(rf.maxDepth, [2,3,4,5])\n             .build())\n\n# Add the grid to the CrossValidator\ncrossval.setEstimatorParamMaps(paramGrid)\n\n# Now let's find and return the best model\nrfModel = crossval.fit(trainingSetDF).bestModel"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":39},{"cell_type":"markdown","source":["#### 2.3.5 Random Forest Cross Validation Evaluation"],"metadata":{}},{"cell_type":"code","source":["# evaluation\nresultsDF = rfModel.transform(testSetDF)\n# Create an RMSE evaluator using the label and predicted columns\nregEval = RMSLEEvaluator(predictionCol=\"predicted_meter_reading\", labelCol=\"meter_reading\")\n\n# Run the evaluator on the DataFrame\nrmsle = regEval.evaluate(resultsDF)\n\nprint(\"Cross Validated Root Mean Squared Logarithmtic Error: %.2f\" % rmsle)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Cross Validated Root Mean Squared Logarithmtic Error: 3.50\n</div>"]}}],"execution_count":41},{"cell_type":"markdown","source":["### 2.4 Gradient-Boosted Trees\n#### 2.4.1 Gradient-Boosted Trees Pipeline"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.regression import GBTRegressor\n\n# Create a DecisionTreeRegressor\ngbt = GBTRegressor()\n\ngbt.setPredictionCol(\"predicted_meter_reading\")\\\n  .setLabelCol(\"meter_reading\")\\\n  .setFeaturesCol(\"features\")\\\n  .setMaxBins(100)\\\n  .setMaxIter(100)\n\n# Create a Pipeline\ngbtPipeline = Pipeline()\n\n# Set the stages of the Pipeline\ngbtPipeline.setStages([vectorizer, gbt])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[139]: Pipeline_fa75699ef85c</div>"]}}],"execution_count":43},{"cell_type":"markdown","source":["#### 2.4.2 Gradient-Boosted Trees Simple Fitting"],"metadata":{}},{"cell_type":"code","source":["# Let's first train on the entire dataset to see what we get\ngbtModel = gbtPipeline.fit(trainingSetDF)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":45},{"cell_type":"markdown","source":["#### 2.4.3 Gradient-Boosted Trees Simple Evaluation"],"metadata":{}},{"cell_type":"code","source":["resultsDF = gbtModel.transform(testSetDF)\n# Create an RMSE evaluator using the label and predicted columns\nregEval = RMSLEEvaluator(predictionCol=\"predicted_meter_reading\", labelCol=\"meter_reading\")\n\n# Run the evaluator on the DataFrame\nrmsle = regEval.evaluate(resultsDF)\n\nprint(\"Simple Root Mean Squared Logarithmtic Error: %.2f\" % rmsle)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Simple Root Mean Squared Logarithmtic Error: 2.35\n</div>"]}}],"execution_count":47},{"cell_type":"markdown","source":["#### 2.4.4 Gradient-Boosted Trees Cross Validation Fitting"],"metadata":{}},{"cell_type":"code","source":["# # Let's just reuse our CrossValidator with the new dtPipeline, RegressionEvaluator regEval, and 3 fold cross validation\n# crossval.setEstimator(gbtPipeline)\n\n# # Let's tune over our dt.maxDepth parameter on the values 2 and 3, create a paramter grid using the ParamGridBuilder\n# paramGrid = (ParamGridBuilder()\n#              .addGrid(gbt.maxDepth, [2,3,4,5])\n#              .build())\n\n# # Add the grid to the CrossValidator\n# crossval.setEstimatorParamMaps(paramGrid)\n\n# # Now let's find and return the best model\n# gbtModel = crossval.fit(trainingSetDF).bestModel"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":["#### 2.4.5 Gradient-Boosted Trees Cross Validation Evaluation"],"metadata":{}},{"cell_type":"code","source":["# # evaluation\n# resultsDF = gbtModel.transform(testSetDF)\n# # Create an RMSE evaluator using the label and predicted columns\n# regEval = RMSLEEvaluator(predictionCol=\"predicted_meter_reading\", labelCol=\"meter_reading\")\n\n# # Run the evaluator on the DataFrame\n# rmsle = regEval.evaluate(resultsDF)\n\n# print(\"Cross Validated Root Mean Squared Logarithmtic Error: %.2f\" % rmsle)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Cross Validated Root Mean Squared Logarithmtic Error: 2.35\n</div>"]}}],"execution_count":51},{"cell_type":"markdown","source":["### 3. Ensemble Model"],"metadata":{}},{"cell_type":"markdown","source":["#### 3.1 Data Preparation"],"metadata":{}},{"cell_type":"code","source":["# lrModel\n# dtModel\n# rfModel\n# gbtModel\nfrom pyspark.sql.functions import monotonically_increasing_id \n\nlrTrainingSetDF = lrModel.transform(trainingSetDF).withColumnRenamed('predicted_meter_reading', 'lr_predicted').select('lr_predicted', \"meter_reading\")\\\n                          .withColumn('id', monotonically_increasing_id())\ndtTrainingSetDF = dtModel.transform(trainingSetDF).withColumnRenamed('predicted_meter_reading', 'dt_predicted').select('dt_predicted')\\\n                          .withColumn('id', monotonically_increasing_id())\nrfTrainingSetDF = rfModel.transform(trainingSetDF).withColumnRenamed('predicted_meter_reading', 'rf_predicted').select('rf_predicted')\\\n                          .withColumn('id', monotonically_increasing_id())\ngbtTrainingSetDF = gbtModel.transform(trainingSetDF).withColumnRenamed('predicted_meter_reading', 'gbt_predicted').select('gbt_predicted')\\\n                          .withColumn('id', monotonically_increasing_id())\n\nlrTestSetDF = lrModel.transform(testSetDF).withColumnRenamed('predicted_meter_reading', 'lr_predicted').select('lr_predicted')\\\n                          .withColumn('id', monotonically_increasing_id())\ndtTestSetDF = dtModel.transform(testSetDF).withColumnRenamed('predicted_meter_reading', 'dt_predicted').select('dt_predicted')\\\n                          .withColumn('id', monotonically_increasing_id())\nrfTestSetDF = rfModel.transform(testSetDF).withColumnRenamed('predicted_meter_reading', 'rf_predicted').select('rf_predicted')\\\n                          .withColumn('id', monotonically_increasing_id())\ngbtTestSetDF = gbtModel.transform(testSetDF).withColumnRenamed('predicted_meter_reading', 'gbt_predicted').select('gbt_predicted', \"meter_reading\")\\\n                          .withColumn('id', monotonically_increasing_id())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":54},{"cell_type":"code","source":["from pyspark.sql.types import StructType\n\n# schema = StructType([])\n# leTrainingSetDF = sqlContext.createDataFrame(sc.emptyRDD(), schema)\n# leTrainingSetDF = leTrainingSetDF.join(lrTrainingSetDF, how=\"left_outer\")\nleTrainingSetDF = lrTrainingSetDF.join(dtTrainingSetDF, \"id\")\nleTrainingSetDF = leTrainingSetDF.join(rfTrainingSetDF, \"id\")\nleTrainingSetDF = leTrainingSetDF.join(gbtTrainingSetDF, \"id\")\nleTrainingSetDF = leTrainingSetDF.drop('id')\n\n# leTestSetDF = sqlContext.createDataFrame(sc.emptyRDD(), schema)\n# leTestSetDF = leTestSetDF.join(lrTrainingSetDF, how=\"left_outer\")\nleTestSetDF = lrTestSetDF.join(dtTestSetDF, \"id\")\nleTestSetDF = leTestSetDF.join(rfTestSetDF, \"id\")\nleTestSetDF = leTestSetDF.join(gbtTestSetDF, \"id\")\nleTestSetDF = leTestSetDF.drop('id')\n\nleVectorizer = VectorAssembler()\nleVectorizer.setInputCols([\"lr_predicted\", \"dt_predicted\", \"rf_predicted\", \"gbt_predicted\"])\nleVectorizer.setOutputCol(\"features\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[145]: VectorAssembler_c23b25aad281</div>"]}}],"execution_count":55},{"cell_type":"markdown","source":["#### 3.2 Linear Ensemble\n##### 3.2.1 Linear Ensemble PipeLine Set Up"],"metadata":{}},{"cell_type":"code","source":["le = LinearRegression(fitIntercept=False)\n\n# Now we set the parameters for the method\nle.setPredictionCol(\"predicted_meter_reading\")\\\n  .setLabelCol(\"meter_reading\")\\\n  .setMaxIter(100)\\\n  .setRegParam(0.15)\n\nlePipeline = Pipeline()\n\nlePipeline.setStages([leVectorizer, le])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[146]: Pipeline_5ab957e4e991</div>"]}}],"execution_count":57},{"cell_type":"markdown","source":["##### 3.2.2 Linear Ensemble Simple Fitting"],"metadata":{}},{"cell_type":"code","source":["leModel = lePipeline.fit(leTrainingSetDF)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":59},{"cell_type":"markdown","source":["##### 3.2.3 Linear Ensemble Simple Evaluation"],"metadata":{}},{"cell_type":"code","source":["# The intercept is as follows:\n# intercept = leModel.stages[1].intercept\n\n# The coefficents (i.e., weights) are as follows:\n\nweights = leModel.stages[1].coefficients\n\n# Create a list of the column names (without PE)\nfeaturesNoLabel = [col for col in leTrainingSetDF.columns if col != \"meter_reading\"]\n\n# Merge the weights and labels\ncoefficents = zip(weights, featuresNoLabel)\n\n#equation = \"y = {intercept}\".format(intercept=intercept)\nvariables = []\nfor x in coefficents:\n    weight = abs(x[0])\n    name = x[1]\n    symbol = \"+\" if (x[0] > 0) else \"-\"\n    equation += (\" {} ({} * {})\".format(symbol, weight, name))\n\nprint(\"Linear Regression Equation: \" + equation)\n\nresultsDF = leModel.transform(leTestSetDF)\n# Create an RMSE evaluator using the label and predicted columns\nregEval = RMSLEEvaluator(predictionCol=\"predicted_meter_reading\", labelCol=\"meter_reading\")\n\n# Run the evaluator on the DataFrame\nrmsle = regEval.evaluate(resultsDF)\n\nprint(\"Simple Root Mean Squared Logarithmtic Error: %.2f\" % rmsle)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Linear Regression Equation: y = -1628.2595464557123 - (81.46769056147313 * air_temperature) + (310.7297353564789 * cloud_coverage) + (49.07117327556077 * dew_temperature) + (0.6854023839988548 * precip_depth_1_hr) - (1.3102359625713624 * sea_level_pressure) - (2.0478121225731805 * wind_direction) + (616.6811932978468 * wind_speed) + (0.031227447032164648 * square_feet) - (1.1441196672897695 * year_built) - (331.46445928163524 * floor_count) + (2458.9197918047203 * meter) + (0.12096192689364511 * lr_predicted) + (1.0324770518027366 * dt_predicted) - (1.3876101018922729 * rf_predicted) + (1.507661937246191 * gbt_predicted) + (0.24074223941725056 * lr_predicted) - (0.16349979577825713 * dt_predicted) - (0.7035176942249738 * rf_predicted) + (1.3062007131798081 * gbt_predicted)\nSimple Root Mean Squared Logarithmtic Error: 2.98\n</div>"]}}],"execution_count":61}],"metadata":{"name":"proj_test","notebookId":3809160049411972},"nbformat":4,"nbformat_minor":0}

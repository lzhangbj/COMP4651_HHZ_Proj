{"cells":[{"cell_type":"code","source":["train_df = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/train.csv')\nbuilding_metadata_df = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/building_metadata.csv')\nweather_train_df = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/weather_train.csv')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["meta_train_df =  building_metadata_df.join(train_df, (building_metadata_df['building_id'] == train_df['building_id']))\ncond = [weather_train_df.site_id == meta_train_df.site_id, weather_train_df.timestamp == meta_train_df.timestamp]\ntrainDF =  weather_train_df.join(meta_train_df, cond)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["datasetDF = trainDF.drop(\"timestamp\", \"site_id\", \"building_id\")\ndatasetDF = datasetDF.na.fill(0)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# ***** vectorizer MODEL ****\nfrom pyspark.ml.feature import VectorAssembler\n\nvectorizer = VectorAssembler()\nvectorizer.setInputCols([\"air_temperature\", \"cloud_coverage\", \"dew_temperature\", \"precip_depth_1_hr\", \"sea_level_pressure\", \n                         \"wind_direction\", \"wind_speed\", \"square_feet\", \"year_built\", \"floor_count\", \"meter\"])\nvectorizer.setOutputCol(\"features\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[15]: VectorAssembler_5c991f09f0d4</div>"]}}],"execution_count":4},{"cell_type":"code","source":["split15DF, split85DF = datasetDF.randomSplit([15., 85.], seed=190)\n\n# Let's cache these datasets for performance\ntestSetDF = split15DF#.cache()\ntrainingSetDF = split85DF#.cache()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["# ***** LINEAR REGRESSION MODEL ****\n\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.regression import LinearRegressionModel\nfrom pyspark.ml import Pipeline\n\n# Let's initialize our linear regression learner\nlr = LinearRegression()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# Now we set the parameters for the method\nlr.setPredictionCol(\"predicted_meter_reading\")\\\n  .setLabelCol(\"meter_reading\")\\\n  .setMaxIter(100)\\\n  .setRegParam(0.15)\n\n\n# We will use the new spark.ml pipeline API. If you have worked with scikit-learn this will be very familiar.\nlrPipeline = Pipeline()\n\nlrPipeline.setStages([vectorizer, lr])\n\n# Let's first train on the entire dataset to see what we get\nlrModel = lrPipeline.fit(trainingSetDF)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["# The intercept is as follows:\nintercept = lrModel.stages[1].intercept\n\n# The coefficents (i.e., weights) are as follows:\nweights = lrModel.stages[1].coefficients\n\n# Create a list of the column names (without PE)\nfeaturesNoLabel = [col for col in datasetDF.columns if col != \"meter_reading\"]\n\n# Merge the weights and labels\ncoefficents = zip(weights, featuresNoLabel)\n\n# Now let's sort the coefficients from greatest absolute weight most to the least absolute weight\n\nequation = \"y = {intercept}\".format(intercept=intercept)\nvariables = []\nfor x in coefficents:\n    weight = abs(x[0])\n    name = x[1]\n    symbol = \"+\" if (x[0] > 0) else \"-\"\n    equation += (\" {} ({} * {})\".format(symbol, weight, name))\n\n# Finally here is our equation\nprint(\"Linear Regression Equation: \" + equation)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Linear Regression Equation: y = -1647.480704504902 - (82.09027861594296 * air_temperature) + (311.7621629198487 * cloud_coverage) + (50.01679396344028 * dew_temperature) + (0.47510420150805366 * precip_depth_1_hr) - (1.3256439485160765 * sea_level_pressure) - (2.062440276979695 * wind_direction) + (624.4465059528753 * wind_speed) + (0.031391908298512974 * primary_use) - (1.1506736508518112 * square_feet) - (333.3409622192619 * year_built) + (2473.900635995334 * floor_count)\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["resultsDF = lrModel.transform(testSetDF)#.select(\"AT\", \"V\", \"AP\", \"RH\", \"PE\", \"Prediction_PE\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["# t = resultsDF.groupBy().agg({'predicted_meter_reading': \"mean\"})\nfrom pyspark.sql.functions import *\n# predictionCol = \"predicted_meter_reading\"\n# labelCol = \"meter_reading\"\n# dataset = resultsDF\n# dataset = dataset.withColumn('result_'+predictionCol, log(col(predictionCol)+1))\n# dataset = dataset.withColumn('result_'+labelCol, log(col(labelCol)+1))\n# dataset = dataset.withColumn('result', (col('result_'+predictionCol) - col('result_'+labelCol)))\n# result = dataset.agg(avg(col(\"result\")))\n# result = result.collect()[0][\"avg(result)\"]\n# print(result)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["\n\n# Now let's compute an evaluation metric for our test dataset\nfrom pyspark.ml.evaluation import Evaluator, RegressionEvaluator\nfrom math import sqrt\nfrom statistics import mean\n\nclass RMSLEEvaluator(Evaluator):\n\n    def __init__(self, predictionCol=\"prediction\", labelCol=\"label\"):\n        self.predictionCol = predictionCol\n        self.labelCol = labelCol\n\n    def _evaluate(self, dataset):\n        \"\"\"\n        Returns a random number. \n        Implement here the true metric\n        \"\"\"\n        new_dataset = dataset.withColumn('result_'+self.predictionCol, log(col(self.predictionCol)+1))\n        new_dataset = new_dataset.withColumn('result_'+self.labelCol, log(col(self.labelCol)+1))\n        new_dataset = new_dataset.withColumn('result', (col('result_'+self.predictionCol) - col('result_'+self.labelCol))**2)\n        \n        result = new_dataset.agg(avg(col(\"result\")))\n        result = result.collect()[0][\"avg(result)\"]\n        return sqrt(result)\n      \n    def isLargerBetter(self):\n        return True\n# Create an RMSE evaluator using the label and predicted columns\nregEval = RMSLEEvaluator(predictionCol=\"predicted_meter_reading\", labelCol=\"meter_reading\")\n\n# Run the evaluator on the DataFrame\nrmse = regEval.evaluate(resultsDF)\n\nprint(\"Root Mean Squared Error: %.2f\" % rmse)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Root Mean Squared Error: 4.27\n</div>"]}}],"execution_count":11}],"metadata":{"name":"proj_test","notebookId":3809160049411972},"nbformat":4,"nbformat_minor":0}
